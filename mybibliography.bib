@techreport{deep-learning-methods-and-applications,
author = {Li Deng, Dong Yu},
title = {Deep Learning: Methods and Applications},
booktitle = {},
year = {2014},
month = {May},
abstract = {

This book is aimed to provide an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria: 1) expertise or knowledge of the authors; 2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and 3) the application areas that have the potential to be impacted significantly by deep learning and that have gained concentrated research efforts, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.

In Chapter 1, we provide the background of deep learning, as intrinsically connected to the use of multiple layers of nonlinear transformations to derive features from the sensory signals such as speech and visual images. In the most recent literature, deep learning is embodied also as representation learning, which involves a hierarchy of features or concepts where higher-level representations of them are defined from lower-level ones and where the same lower-level representations help to define higher-level ones. In Chapter 2, a brief historical account of deep learning is presented. In particular, selected chronological development of speech recognition is used to illustrate the recent impact of deep learning that has become a dominant technology in speech recognition industry within only a few years since the start of a collaboration between academic and industrial researchers in applying deep learning to speech recognition. In Chapter 3, a three-way classification scheme for a large body of work in deep learning is developed. We classify a growing number of deep learning techniques into unsupervised, supervised, and hybrid categories, and present qualitative descriptions and a literature survey for each category. From Chapter 4 to Chapter 6, we discuss in detail three popular deep networks and related learning methods, one in each category. Chapter 4 is devoted to deep autoencoders as a prominent example of the unsupervised deep learning techniques. Chapter 5 gives a major example in the hybrid deep network category, which is the discriminative feed-forward neural network for supervised learning with many layers initialized using layer-by-layer generative, unsupervised pre-training. In Chapter 6, deep stacking networks and several of the variants are discussed in detail, which exemplify the discriminative or supervised deep learning techniques in the three-way categorization scheme.

In Chapters 7-11, we select a set of typical and successful applications of deep learning in diverse areas of signal and information processing and of applied artificial intelligence. In Chapter 7, we review the applications of deep learning to speech and audio processing, with emphasis on speech recognition organized according to several prominent themes. In Chapters 8, we present recent results of applying deep learning to language modeling and natural language processing. Chapter 9 is devoted to selected applications of deep learning to information retrieval including Web search. In Chapter 10, we cover selected applications of deep learning to image object recognition in computer vision. Selected applications of deep learning to multi-modal processing and multi-task learning are reviewed in Chapter 11. Finally, an epilogue is given in Chapter 12 to summarize what we presented in earlier chapters and to discuss future challenges and directions.


},
publisher = {NOW Publishers},
url = {https://www.microsoft.com/en-us/research/publication/deep-learning-methods-and-applications/},
address = {},
pages = {},
journal = {},
volume = {},
chapter = {},
isbn = {},
}

@inproceedings{37648,
title = {Reading Digits in Natural Images with Unsupervised Feature Learning},
author  = {Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y. Ng},
year  = 2011,
URL = {http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf},
booktitle = {NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011}
}

@article{DBLP:journals/corr/GoodfellowBIAS13,
  author    = {Ian J. Goodfellow and
               Yaroslav Bulatov and
               Julian Ibarz and
               Sacha Arnoud and
               Vinay D. Shet},
  title     = {Multi-digit Number Recognition from Street View Imagery using Deep
               Convolutional Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1312.6082},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.6082},
  timestamp = {Fri, 04 Dec 2015 12:23:11 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/GoodfellowBIAS13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Article{Fukushima1980,
author="Fukushima, Kunihiko",
title="Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position",
journal="Biological Cybernetics",
year="1980",
volume="36",
number="4",
pages="193--202",
abstract="A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by ``learning without a teacher'', and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname ``neocognitron''. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of ``S-cells'', which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of ``C-cells'' similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any ``teacher'' during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.",
issn="1432-0770",
doi="10.1007/BF00344251",
url="http://dx.doi.org/10.1007/BF00344251"
}

@INPROCEEDINGS{Lecun98gradient-basedlearning,
    author = {Yann Lecun and Léon Bottou and Yoshua Bengio and Patrick Haffner},
    title = {Gradient-based learning applied to document recognition},
    booktitle = {Proceedings of the IEEE},
    year = {1998},
    pages = {2278--2324}
}

@misc{45166,
title = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems},
author  = {Martín Abadi and Ashish Agarwal and Paul Barham and Eugene Brevdo and Zhifeng Chen and Craig Citro and Greg Corrado and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Ian Goodfellow and Andrew Harp and Geoffrey Irving and Michael Isard and Yangqing Jia and Rafal Jozefowicz and Lukasz Kaiser and Manjunath Kudlur and Josh Levenberg and Dan Mané and Rajat Monga and Sherry Moore and Derek Murray and Chris Olah and Mike Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and Paul Tucker and Vincent Vanhoucke and Vijay Vasudevan and Fernanda Viégas and Oriol Vinyals and Pete Warden and Martin Wattenberg and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
year  = 2015,
URL = {http://download.tensorflow.org/paper/whitepaper2015.pdf}
}

@manual{python,
    abstract = {{Python is an interpreted, object-oriented, high-level programming language with dynamic semantics. Its high-level built in data structures, combined with dynamic typing and dynamic binding, make it very attractive for rapid application development, as well as for use as a scripting or glue language to connect existing components together. Python's simple, easy to learn syntax emphasizes readability and therefore reduces the cost of program maintenance. Python supports modules and packages, which encourages program modularity and code reuse. The Python interpreter and the extensive standard library are available in source or binary form without charge for all major platforms, and can be freely distributed.

This reference manual describes the syntax and ``core semantics'' of the language. It is terse, but attempts to be exact and complete. The semantics of non-essential built-in object types and of the built-in functions and modules are described in the Python Library Reference. For an informal introduction to the language, see the Python Tutorial. For C or C++ programmers, two additional manuals exist: Extending and Embedding the Python Interpreter describes the high-level picture of how to write a Python extension module, and the Python/C API Reference Manual describes the interfaces available to C/C++ programmers in detail.}},
    author = {van Rossum, Guido},
    citeulike-article-id = {500686},
    citeulike-linkout-0 = {http://docs.python.org/ref/ref.html},
    day = {29},
    edition = {2.4.3},
    editor = {Drake, Fred L.},
    keywords = {programming},
    month = mar,
    posted-at = {2006-07-20 10:33:13},
    priority = {0},
    title = {{Python Reference Manual}},
    url = {http://docs.python.org/ref/ref.html},
    year = {2006}
}


@article{Srivastava2014,
 author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
 title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2014},
 volume = {15},
 number = {1},
 month = jan,
 year = {2014},
 issn = {1532-4435},
 pages = {1929--1958},
 numpages = {30},
 url = {http://dl.acm.org/citation.cfm?id=2627435.2670313},
 acmid = {2670313},
 publisher = {JMLR.org},
 keywords = {deep learning, model combination, neural networks, regularization},
}
@inproceedings{Ng:2004:FSL:1015330.1015435,
 author = {Ng, Andrew Y.},
 title = {Feature Selection, L1 vs. L2 Regularization, and Rotational Invariance},
 booktitle = {Proceedings of the Twenty-first International Conference on Machine Learning},
 series = {ICML '04},
 year = {2004},
 isbn = {1-58113-838-5},
 location = {Banff, Alberta, Canada},
 pages = {78--},
 url = {http://doi.acm.org/10.1145/1015330.1015435},
 doi = {10.1145/1015330.1015435},
 acmid = {1015435},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{chauhan2013moving,
  title={Moving object tracking using gaussian mixture model and optical flow},
  author={Chauhan, Abhishek Kumar and Krishan, Prashant},
  journal={International Journal of Advanced Research in Computer Science and Software Engineering},
  volume={3},
  number={4},
  year={2013}
}

@inproceedings{lee2009histogram,
  title={Histogram-based interest point detectors},
  author={Lee, Wei-Ting and Chen, Hwann-Tzong},
  booktitle={Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
  pages={1590--1596},
  year={2009},
  organization={IEEE}
}

@phdthesis{rout2013survey,
  title={A survey on object detection and tracking algorithms},
  author={Rout, Rupesh Kumar},
  year={2013}
}

@inproceedings{sen2004robust,
  title={Robust techniques for background subtraction in urban traffic video},
  author={Sen-Ching, S Cheung and Kamath, Chandrika},
  booktitle={Electronic Imaging 2004},
  pages={881--892},
  year={2004},
  organization={International Society for Optics and Photonics}
}

@article{joshi2012survey,
  title={A survey on moving object detection and tracking in video surveillance system},
  author={Joshi, Kinjal A and Thakore, Darshak G},
  journal={International Journal of Soft Computing and Engineering},
  volume={2},
  number={3},
  pages={44--48},
  year={2012},
  publisher={Citeseer}
}

@article{rakibe2013background,
  title={Background subtraction algorithm based human motion detection},
  author={Rakibe, Rupali S and Patil, Bharati D},
  journal={International Journal of scientific and research publications},
  volume={3},
  number={5},
  year={2013},
  publisher={Citeseer}
}

@article{paragios2000geodesic,
  title={Geodesic active contours and level sets for the detection and tracking of moving objects},
  author={Paragios, Nikos and Deriche, Rachid},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={22},
  number={3},
  pages={266--280},
  year={2000},
  publisher={IEEE}
}

@article{zhu1996region,
  title={Region competition: Unifying snakes, region growing, and Bayes/MDL for multiband image segmentation},
  author={Zhu, Song Chun and Yuille, Alan},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={18},
  number={9},
  pages={884--900},
  year={1996},
  publisher={IEEE}
}

@article{kim2002fast,
  title={Fast and automatic video object segmentation and tracking for content-based applications},
  author={Kim, Changick and Hwang, Jenq-Neng},
  journal={IEEE transactions on circuits and systems for video technology},
  volume={12},
  number={2},
  pages={122--129},
  year={2002},
  publisher={IEEE}
}

@inproceedings{srinivasan2009improved,
  title={Improved background subtraction techniques for security in video applications},
  author={Srinivasan, K and Porkumaran, K and Sainarayanan, G},
  booktitle={2009 3rd International Conference on Anti-counterfeiting, Security, and Identification in Communication},
  pages={114--117},
  year={2009},
  organization={IEEE}
}

@inproceedings{zhan2007improved,
  title={An improved moving object detection algorithm based on frame difference and edge detection},
  author={Zhan, Chaohui and Duan, Xiaohui and Xu, Shuoyu and Song, Zheng and Luo, Min},
  booktitle={Image and Graphics, 2007. ICIG 2007. Fourth International Conference on},
  pages={519--523},
  year={2007},
  organization={IEEE}
}

@article{bushrasurvey,
  title={A Survey on Object Detection and Classification Methods from Video Stream},
  author={Bushra, Tasnia and Khan, Muhib Hassan}
}